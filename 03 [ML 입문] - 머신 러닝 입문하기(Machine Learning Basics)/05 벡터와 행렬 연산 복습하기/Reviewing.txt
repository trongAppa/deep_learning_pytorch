1) 벡터와 행렬과 텐서
벡터는 크기와 방향을 가진 양
행렬은 행과 열을 가지는 2차원 형상
텐서는 파이썬에서는 3차원 이상의 배열

2) 텐서(Tensor)

In [1]: import numpy as np

- 0차원 텐서(스칼라)
스칼라는 하나의 실수값으로 이루어진 데이터
축(axis)의 개수 또는 텐서의 차원

- 1차원 텐서(벡터)
벡터의 차원과 텐서의 차원의 정의로 인해 혼동할 수 있는데 벡터에서의 차원은 하나의 축에 놓인 원소의 개수를 의미
텐서에서의 차원은 축의 개수를 의미

- 2차원 텐서(행렬)
행과 열이 존재하는 벡터의 배열

- 3차원 텐서(다차원 배열)
행렬 또는 2차원 텐서를 단위로 한 번 더 배열하면 3차원 텐서
데이터 사이언스 분야 한정으로 주로 3차원 이상의 배열을 텐서
3차원 텐서의 구조를 이해하지 않으면, 복잡한 인공 신경망의 입, 출력값을 이해하는 것이 쉽지 않음

- 그 이상의 텐서
3차원 텐서를 배열로 합치면 4차원 텐서
4차원 텐서를 배열로 합치면 5차원 텐서
다차원 배열로서 계속해서 확장가능

- PyTorch에서의 텐서
2챕터의 '텐서 조작하기' 실습을 참고

- 텐서 시각화 : tensor.png

3) 벡터와 행렬의 연산
- 벡터와 행렬의 덧셈과 뺄셈
같은 크기의 두 개의 벡터나 행렬은 덧셈과 뺄셈 가능, 같은 위치의 원소끼리 연산

- 벡터의 내적과 행렬의 곱셈
벡터의 내적은 연산을 점(dot)으로 표현하여 a·b로 표현
내적이 성립하기 위해서는 두 벡터의 차원이 같아야함
행렬의 곱셈을 이해하기 위해서는 벡터의 내적을 이해
행렬의 곱셈은 딥 러닝을 이해하기 위해 필수적인 개념이므로 반드시 숙지
두 행렬의 곱 A·B이 성립되기 위해서는 행렬 A의 열의 개수와 행렬 B의 행의 개수는 같아야 한다.
두 행렬의 곱 A·B의 결과로 나온 행렬 AB의 크기는 A의 행의 개수와 B의 열의 개수를 가진다.

4) 다중 선형 회귀 행렬 연산으로 이해하기
독립 변수가 2개 이상일 때, 1개의 종속 변수를 예측하는 문제를 행렬의 곱셈으로 표현이 가능
y = ax + b 인공 신경망도 본질적으로 행렬 연산표현 가능

5) 샘플(Sample)과 특성(Feature)
머신 러닝에서는 데이터를 셀 수 있는 단위로 구분할 때, 각각을 샘플
종속 변수 y를 예측하기 위한 각각의 독립 변수 x를 특성

6) 가중치와 편향 행렬의 크기 결정
두 행렬의 곱 J·K이 성립되기 위해서는 행렬 J의 열의 개수와 행렬 K의 행의 개수는 같아야 한다.
두 행렬의 곱 J·K의 결과로 나온 행렬 JK의 크기는 J의 행의 개수와 K의 열의 개수를 가진다.
두 행렬의 곱의 결과로서 나온 행렬의 열의 크기는 행렬의 곱셈에서 뒤에 있는 행렬의 열의 크기와 동일
출력 행렬 Y로부터 W행렬의 열의 크기가 결정
입력 행렬과 출력 행렬의 크기로부터 가중치 행렬과 편향 행렬의 크기를 추정할 수 있다면, 딥 러닝 모델을 구현하였을 때 해당 모델에 존재하는 총 매개변수의 개수를 계산 쉬움
딥 러닝 모델의 총 매개변수의 개수는 해당 모델에 존재하는 가중치 행렬과 편향 행렬의 모든 원소의 수